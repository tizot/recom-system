{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# User's papers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Select author's papers with the following command in a shell (the raw file is `publications-v8.txt` and the author is Gabriella Pasi in this example):  \n",
    "`awk -v RS='' -v ORS='\\n\\n' '/(G\\. |Gabriella )Pasi\\W/' publications-v8.txt > ../data/pasi_papers.txt`  \n",
    "The result file must be located in the folder `./data/`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import os, re, time\n",
    "import pandas as pd\n",
    "\n",
    "import MySQLdb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def list2paper(l, r_index=None, r_author=None, r_title=None, r_abstract=None, r_cite=None):\n",
    "    \"\"\"\n",
    "    Transform a raw data paper formatted as a list into dict\n",
    "    \"\"\"\n",
    "    p = {'index': None, 'authors': [], 'title': None, 'abstract': None, 'citations': []}\n",
    "    \n",
    "    if r_index is None:\n",
    "        r_index = re.compile('^#index(.*)')\n",
    "    if r_author is None:\n",
    "        r_author = re.compile('^#@(.*)')\n",
    "    if r_title is None:\n",
    "        r_title = re.compile('^#\\*(.*)')\n",
    "    if r_abstract is None:\n",
    "        r_abstract = re.compile('^#!(.*)')\n",
    "    if r_cite is None:\n",
    "        r_cite = re.compile('^#%(.*)')\n",
    "        \n",
    "    for s in l:\n",
    "        m_index = r_index.match(s)\n",
    "        if m_index is not None:\n",
    "            p['index'] = m_index.group(1)\n",
    "        \n",
    "        m_author = r_author.match(s)\n",
    "        if m_author is not None:\n",
    "            p['authors'] = [a.strip() for a in m_author.group(1).split(',')]\n",
    "        \n",
    "        m_title = r_title.match(s)\n",
    "        if m_title is not None:\n",
    "            p['title'] = m_title.group(1)\n",
    "        \n",
    "        m_abstract = r_abstract.match(s)\n",
    "        if m_abstract is not None:\n",
    "            p['abstract'] = m_abstract.group(1)\n",
    "        \n",
    "        m_cite = r_cite.match(s)\n",
    "        if m_cite is not None:\n",
    "            p['citations'].append(m_cite.group(1))\n",
    "    \n",
    "    return p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_author_papers(author_name, author_slug, input_file):\n",
    "    \"\"\"\n",
    "    Return the list of papers written by the author (list of dicts)\n",
    "    \"\"\"\n",
    "    # Split result into a list of lists (each sublist is a paper)\n",
    "    papers = []\n",
    "    with open(input_file, 'r') as f:\n",
    "        content = f.readlines()\n",
    "        p = []\n",
    "        for l in content:\n",
    "            if l.strip() != '':\n",
    "                p.append(l)\n",
    "            else:\n",
    "                papers.append(p)\n",
    "                p = [] \n",
    "    \n",
    "    papers = [list2paper(l) for l in papers]\n",
    "    \n",
    "    author_papers = []\n",
    "    papers_without_abstract = []\n",
    "    \n",
    "    for p in papers:\n",
    "        if author_name in p['authors']:\n",
    "            if p['abstract'] is not None:\n",
    "                author_papers.append(p)\n",
    "            else:\n",
    "                papers_without_abstract.append(p)\n",
    "    \n",
    "    return author_papers, papers_without_abstract"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "author_papers, _ = get_author_papers('Gabriella Pasi', 'pasi', '../data/pasi_papers.txt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate citations file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def generate_citations_file(author_papers, author_slug):\n",
    "    citations = []\n",
    "    for p in author_papers:\n",
    "        for c in p['citations']:\n",
    "            citations.append([p['index'], c])\n",
    "    \n",
    "    pd.DataFrame(citations).to_csv('../data/' + author_slug + '_citations.csv', header=['citing', 'cited'], index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "generate_citations_file(author_papers, 'pasi')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get cited papers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_cited_papers(cited):\n",
    "    db = MySQLdb.connect(user='root', passwd='root', db='dblp-v8')\n",
    "    c = db.cursor()\n",
    "\n",
    "    start_time = time.time()\n",
    "\n",
    "    # Select papers authored by user\n",
    "    c.execute(\"SELECT id, title, abstract FROM papers p WHERE p.abstract != '' AND p.id IN (\" + ','.join([\"%s\"] * len(cited)) + \")\", tuple(cited))\n",
    "    return c.fetchall()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "citations = pd.read_csv('../data/pasi_citations.csv')\n",
    "cited = citations['cited'].unique()\n",
    "cited_papers = get_cited_papers(cited)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Non relevant papers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_bad_papers(input_file):\n",
    "    \"\"\"\n",
    "    Return the list of \"bad\" papers written (list of dicts)\n",
    "    \"\"\"\n",
    "    # Split result into a list of lists (each sublist is a paper)\n",
    "    papers = []\n",
    "    with open(input_file, 'r') as f:\n",
    "        content = f.readlines()\n",
    "        p = []\n",
    "        for l in content:\n",
    "            if l.strip() != '':\n",
    "                p.append(l)\n",
    "            else:\n",
    "                papers.append(p)\n",
    "                p = [] \n",
    "    \n",
    "    papers = [list2paper(l) for l in papers]\n",
    "    \n",
    "    papers_with_abstract = []\n",
    "    \n",
    "    for p in papers:\n",
    "        if p['abstract'] is not None:\n",
    "            papers_with_abstract.append(p)\n",
    "    \n",
    "    return papers_with_abstract"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "bad_papers = get_bad_papers('../data/bad_papers.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def get_bad_cited_papers(bad_papers):\n",
    "    citations = []\n",
    "    for p in bad_papers:\n",
    "        for c in p['citations']:\n",
    "            citations.append([p['index'], c])\n",
    "    \n",
    "    citations_df = pd.DataFrame(citations, columns=['citing', 'cited'])\n",
    "    cited = citations_df['cited'].unique()\n",
    "    \n",
    "    db = MySQLdb.connect(user='root', passwd='root', db='dblp-v8')\n",
    "    c = db.cursor()\n",
    "\n",
    "    start_time = time.time()\n",
    "\n",
    "    c.execute(\"SELECT id, title, abstract FROM papers p WHERE p.abstract != '' AND p.id IN (\" + ','.join([\"%s\"] * len(cited)) + \")\", tuple(cited))\n",
    "    \n",
    "    return c.fetchall()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "bad_cited_papers = get_bad_cited_papers(bad_papers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "bad_cited_papers = [{'index': p[0], 'title': p[1], 'abstract': p[2]} for p in bad_cited_papers]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def format_data(author_papers, citations, cited_papers, bad_papers, bad_cited_papers):\n",
    "    a_papers = tuple([(p['index'], p['title'], p['abstract']) for p in author_papers])\n",
    "    cites = tuple([(c[0], c[1]) for c in citations.as_matrix()])\n",
    "    b_papers = tuple([(p['index'], p['title'], p['abstract']) for p in (bad_papers + bad_cited_papers)])\n",
    "    \n",
    "    return a_papers, cites, cited_papers, b_papers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from dataset_tools import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "author_papers, cites, cited_papers, bad_papers = format_data(author_papers, citations, cited_papers, bad_papers, bad_cited_papers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Generate global vocabulary\n",
    "author_vocab = generate_vocab(author_papers)\n",
    "global_vocab = generate_vocab(bad_papers)\n",
    "tokens = list(set(author_vocab + global_vocab))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preparing dataset...\n",
      "Processed 74 papers in 0.513s\n",
      "Processed 766 citation relations in 0.001s\n",
      "Processed 351 cited papers in 1.919s\n",
      "Processed 786 papers in 4.070s\n",
      "Done.\n",
      "\n",
      "Building computable dataset...\n",
      "Generated dataset with 351 samples in 0.523s\n",
      "\n",
      "Saving dataset to file: ../data/datasets/dataset-pasi.npz\n",
      "Done.\n"
     ]
    }
   ],
   "source": [
    "num_entries = 6\n",
    "output_file = '../data/datasets/dataset-pasi'\n",
    "\n",
    "print(\"Preparing dataset...\")\n",
    "papers_feat, citations_feat, bad_feat, ngrams = prepare_dataset(author_papers, cites, cited_papers, bad_papers, tokens)\n",
    "\n",
    "print(\"\")\n",
    "num_entries = 6\n",
    "print(\"Building computable dataset...\")\n",
    "inputs = build_dataset(papers_feat, citations_feat, bad_feat, num_entries)\n",
    "\n",
    "print(\"\")\n",
    "print(\"Saving dataset to file: \" + output_file + \".npz\")\n",
    "dataset_to_file(inputs, ngrams, output_file)\n",
    "print(\"Done.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
